{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jemima/Data/scripts_data_results/scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from pickle import dump, load\n",
    "import xgboost as xgb\n",
    "from hmmlearn import hmm\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import run_model as rm\n",
    "importlib.reload(rm)\n",
    "\n",
    "this_path = os.getcwd()\n",
    "print(this_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_path = '../model_versions/std_scaler.pkl'\n",
    "model_path = '../model_versions/final_model.json'\n",
    "\n",
    "df_train = pd.read_csv(\"../training_data/training_cleaned_scaled_fsel.csv\")\n",
    "var_cols = [c for c in df_train.columns if c not in ['class']]\n",
    "\n",
    "for year in np.linspace(2016, 2023, 8).astype(int):\n",
    "    f_path, outpath = f\"../production_data/riverstate/{year}.nc\", f\"../test_results/riverstate/{year}.nc\"\n",
    "    rm.run_model(f_path, outpath, var_cols, scaler_path, model_path, save_results=True, plot_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_res(dirpath):\n",
    "    f_list = sorted([filename for filename in os.listdir(dirpath)])\n",
    "    da_list = []\n",
    "    for fname in f_list:\n",
    "        da_list.append(xr.open_dataarray(os.path.join(dirpath, fname), mask_and_scale=True))\n",
    "    da_merge = xr.concat(da_list, dim='time') \n",
    "    return da_merge\n",
    "\n",
    "da_res = stack_res(\"../test_results/riverstate/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state space\n",
    "states = ['Bare', 'Standard Mangroves', 'Tall Mangroves/Forest']\n",
    "n_states = len(states)\n",
    "print('Number of hidden states :', n_states)\n",
    "\n",
    "# Define the observation space\n",
    "observations = [0, 1, 2]\n",
    "n_observations = len(observations)\n",
    "print('Number of observations  :', n_observations)\n",
    "\n",
    "# Define the initial state distribution\n",
    "state_probability = np.array([0.15, 0.4, 0.45])\n",
    "print(\"State probability:\", state_probability)\n",
    "\n",
    "# Define the state transition probabilities\n",
    "transition_probability = np.array([[1.0, 0.0, 0.0],\n",
    "                                   [0.4, 0.6, 0.0],\n",
    "                                   [0.1, 0.0, 0.9]])\n",
    "print(\"\\nTransition probability:\\n\", transition_probability)\n",
    "\n",
    "# Define the observation likelihoods\n",
    "emission_probability = np.array([[1.0, 0.0, 0.0],\n",
    "                                 [0.3, 0.6, 0.1],\n",
    "                                 [0.1, 0.1, 0.8]])\n",
    "print(\"\\nEmission probability:\\n\", emission_probability)\n",
    "\n",
    "model = hmm.CategoricalHMM(n_components=n_states)\n",
    "model.startprob_ = state_probability\n",
    "model.transmat_ = transition_probability\n",
    "model.emissionprob_ = emission_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply HMM to data\n",
    "arr = da_res.to_numpy()\n",
    "print(arr.shape)\n",
    "\n",
    "for i in range(arr.shape[2]):\n",
    "    for j in range(arr.shape[1]):\n",
    "        if str(arr[0, j, i]) != 'nan':\n",
    "            try:\n",
    "                arr[:, j, i] = model.predict(arr[:, j, i].reshape(-1, 1).astype(int))\n",
    "            except IndexError:\n",
    "                continue\n",
    "    print('\\r Progress complete (%) - ' + str((i / arr.shape[2]) * 100), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_hmm = xr.DataArray(arr, coords={\n",
    "    'time':da_res.time,\n",
    "    'y':da_res.y.values,\n",
    "    'x':da_res.x.values\n",
    "})\n",
    "\n",
    "da_hmm.to_netcdf(\"../final_results/hmm_stack.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jofenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
